{
  "hash": "07be72385ec9b14cec2eee08be9d0631",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Barnacle\"\ndescription: \"final push\"\ncategories: [e5, coral]\n#citation: \ndate: 11-29-2025\nimage: http://gannet.fish.washington.edu/seashell/snaps/Monosnap_Image_2025-11-30_08-27-36.png # finding a good image\nauthor:\n  - name: Steven Roberts\n    url: \n    orcid: 0000-0001-8302-1138\n    affiliation: Professor, UW - School of Aquatic and Fishery Sciences\n    affiliation-url: https://robertslab.info\n  #url:  # self-defined\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\nformat:\n  html:\n    code-fold: FALSE\n    code-tools: true\n    code-copy: true\n    highlight-style: github\n    code-overflow: wrap\n#runtime: shiny\n---\n\n## Trying to build alternative tensor\n\n\n\n``` python\n#!/usr/bin/env python3\n\"\"\"\nAlternative tensor construction: (genes × timepoints × samples)\nEach sample becomes a separate slice instead of grouping by species.\n\"\"\"\nimport argparse\nimport json\nimport os\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom barnacle.decomposition import SparseCP\n\n\ndef read_normalized_csv(path: str) -> pd.DataFrame:\n    df = pd.read_csv(path)\n    if 'group_id' not in df.columns:\n        raise ValueError(f\"Expected 'group_id' column in {path}\")\n    df = df.set_index('group_id')\n    return df\n\n\ndef parse_sample_timepoint(column_name: str) -> Tuple[str, str, int]:\n    tp_index = column_name.rfind('-TP')\n    if tp_index == -1:\n        raise ValueError(f\"Expected TP# token at end of column: {column_name}\")\n\n    time_token = column_name[tp_index + 1:]\n    if not time_token.startswith('TP'):\n        raise ValueError(f\"Expected TP# token at end of column: {column_name}\")\n    try:\n        tp = int(time_token.replace('TP', ''))\n    except Exception as exc:\n        raise ValueError(f\"Failed to parse timepoint from {column_name}\") from exc\n\n    sample_id = column_name[:tp_index]\n    sample_prefix = sample_id.split('-')[0]\n    species_map = {'ACR': 'apul', 'POR': 'peve', 'POC': 'ptua'}\n    if sample_prefix not in species_map:\n        raise ValueError(f\"Unknown species prefix in column: {column_name}\")\n\n    species = species_map[sample_prefix]\n    return species, sample_id, tp\n\n\ndef build_tensor_by_sample(\n    df: pd.DataFrame,\n    expected_timepoints: List[int],\n) -> Tuple[np.ndarray, List[str], Dict[int, Dict[str, str]], List[str]]:\n    \"\"\"\n    Build tensor with shape (genes, timepoints, samples).\n    Each unique sample becomes a slice, with timepoints as rows.\n    \"\"\"\n    common_genes = sorted(list(df.index))\n\n    # Collect all unique samples across all species\n    sample_data = {}  # {sample_id: {species: str, columns: {tp: col_name}}}\n    \n    for col in df.columns:\n        try:\n            species, sample_id, tp = parse_sample_timepoint(col)\n            if tp in expected_timepoints:\n                if sample_id not in sample_data:\n                    sample_data[sample_id] = {\n                        'species': species,\n                        'columns': {}\n                    }\n                sample_data[sample_id]['columns'][tp] = col\n        except ValueError:\n            continue\n\n    # Sort samples by species, then by sample_id\n    sorted_samples = sorted(\n        sample_data.keys(),\n        key=lambda sid: (sample_data[sid]['species'], sid)\n    )\n\n    # Build sample labels and metadata\n    sample_labels: List[str] = []\n    sample_metadata: Dict[int, Dict[str, str]] = {}\n    \n    for idx, sample_id in enumerate(sorted_samples):\n        species = sample_data[sample_id]['species']\n        sample_labels.append(f\"{species}_{sample_id}\")\n        sample_metadata[idx] = {\n            'species': species,\n            'sample_id': sample_id,\n        }\n\n    n_genes = len(common_genes)\n    n_time = len(expected_timepoints)\n    n_samples = len(sorted_samples)\n\n    if n_samples == 0:\n        raise ValueError(\"No samples with valid timepoints found\")\n\n    # Tensor shape: (genes, timepoints, samples)\n    tensor = np.empty((n_genes, n_time, n_samples), dtype=float)\n    tensor[:] = np.nan\n\n    # Fill tensor\n    for s_idx, sample_id in enumerate(sorted_samples):\n        columns = sample_data[sample_id]['columns']\n        for t_idx, tp in enumerate(expected_timepoints):\n            col = columns.get(tp)\n            if col is None:\n                continue\n            values = df.loc[common_genes, col].to_numpy(dtype=float)\n            tensor[:, t_idx, s_idx] = values\n\n    # Replace NaNs with zeros\n    tensor = np.nan_to_num(tensor, nan=0.0)\n    return tensor, sample_labels, sample_metadata, common_genes\n\n\ndef run_sparse_cp(\n    tensor: np.ndarray,\n    rank: int,\n    lambda_gene: float,\n    lambda_time: float,\n    lambda_sample: float,\n    max_iter: int,\n    tol: float,\n    seed: int,\n):\n    \"\"\"\n    Note: lambda order now matches tensor dimensions: [gene, time, sample]\n    \"\"\"\n    model = SparseCP(\n        rank=rank,\n        lambdas=[lambda_gene, lambda_time, lambda_sample],\n        nonneg_modes=[0],\n        n_initializations=3,\n        random_state=seed,\n        n_iter_max=max_iter,\n        tol=tol,\n    )\n    decomposition = model.fit_transform(tensor, verbose=1)\n    return model, decomposition\n\n\ndef save_outputs(\n    output_dir: str,\n    tensor: np.ndarray,\n    sample_labels: List[str],\n    sample_metadata: Dict[int, Dict[str, str]],\n    genes: List[str],\n    model,\n    decomposition,\n):\n    os.makedirs(output_dir, exist_ok=True)\n    factors_dir = os.path.join(output_dir, 'barnacle_factors')\n    figs_dir = os.path.join(output_dir, 'figures')\n    os.makedirs(factors_dir, exist_ok=True)\n    os.makedirs(figs_dir, exist_ok=True)\n\n    np.save(os.path.join(output_dir, 'multiomics_tensor.npy'), tensor)\n\n    # Extract factors: order is [genes, timepoints, samples]\n    gene_factors = pd.DataFrame(decomposition.factors[0], index=genes)\n    time_factors = pd.DataFrame(decomposition.factors[1], \n                               index=[f'TP{t}' for t in range(1, tensor.shape[1] + 1)])\n    sample_factors = pd.DataFrame(decomposition.factors[2], index=sample_labels)\n\n    gene_factors.to_csv(os.path.join(factors_dir, 'gene_factors.csv'))\n    time_factors.to_csv(os.path.join(factors_dir, 'time_factors.csv'))\n    sample_factors.to_csv(os.path.join(factors_dir, 'sample_factors.csv'))\n\n    # Compute component weights\n    weights_attr = getattr(decomposition, 'weights', None)\n    if weights_attr is not None:\n        weights = np.asarray(weights_attr).astype(float).ravel()\n        if np.allclose(weights, weights[0]) if len(weights) > 0 else True:\n            weights = None\n    else:\n        weights = None\n\n    if weights is None:\n        gene_norms = np.linalg.norm(gene_factors.values, axis=0)\n        time_norms = np.linalg.norm(time_factors.values, axis=0)\n        sample_norms = np.linalg.norm(sample_factors.values, axis=0)\n        weights = gene_norms * time_norms * sample_norms\n\n    pd.DataFrame({'weight': weights}).to_csv(\n        os.path.join(factors_dir, 'component_weights.csv'), index=False)\n\n    # Sample mapping\n    mapping_rows = []\n    for idx, label in enumerate(sample_labels):\n        mapping_rows.append({\n            'sample_index': idx,\n            'label': label,\n            'species': sample_metadata[idx]['species'],\n            'sample_id': sample_metadata[idx]['sample_id'],\n        })\n    pd.DataFrame(mapping_rows).to_csv(\n        os.path.join(factors_dir, 'sample_mapping.csv'), index=False)\n\n    # Metadata\n    raw_loss = getattr(model, 'loss_', None)\n    if raw_loss is None:\n        final_loss = None\n    else:\n        try:\n            if isinstance(raw_loss, (list, tuple, np.ndarray)) and len(raw_loss) > 0:\n                final_loss = float(raw_loss[-1])\n            else:\n                final_loss = float(raw_loss)\n        except Exception:\n            final_loss = None\n\n    metadata = {\n        'timestamp': datetime.utcnow().isoformat() + 'Z',\n        'tensor_shape': list(map(int, tensor.shape)),\n        'tensor_structure': '(genes, timepoints, samples)',\n        'n_components': int(gene_factors.shape[1]),\n        'model_converged': bool(getattr(model, 'converged_', False)),\n        'final_loss': final_loss,\n    }\n    with open(os.path.join(factors_dir, 'metadata.json'), 'w') as fh:\n        json.dump(metadata, fh, indent=2)\n\n    # Figures\n    plt.figure(figsize=(6, 4))\n    plt.bar(np.arange(len(weights)), weights)\n    plt.xlabel('Component')\n    plt.ylabel('Weight')\n    plt.title('Component Weights')\n    plt.tight_layout()\n    plt.savefig(os.path.join(figs_dir, 'component_weights.png'), dpi=200)\n    plt.close()\n\n    # Time loadings across components\n    plt.figure(figsize=(7, 4))\n    for k in range(time_factors.shape[1]):\n        plt.plot(range(1, time_factors.shape[0] + 1), \n                time_factors.iloc[:, k], marker='o', label=f'C{k+1}')\n    plt.xticks(range(1, time_factors.shape[0] + 1))\n    plt.xlabel('Timepoint')\n    plt.ylabel('Loading')\n    plt.title('Time Loadings by Component')\n    plt.legend(ncols=2, fontsize=8)\n    plt.tight_layout()\n    plt.savefig(os.path.join(figs_dir, 'time_loadings.png'), dpi=200)\n    plt.close()\n\n    # Sample loadings colored by species\n    fig, ax = plt.subplots(figsize=(10, 6))\n    species_colors = {'apul': 'C0', 'peve': 'C1', 'ptua': 'C2'}\n    \n    for k in range(sample_factors.shape[1]):\n        for idx, label in enumerate(sample_labels):\n            species = sample_metadata[idx]['species']\n            ax.scatter(k, sample_factors.iloc[idx, k], \n                      c=species_colors[species], alpha=0.6, s=50)\n    \n    ax.set_xlabel('Component')\n    ax.set_ylabel('Sample Loading')\n    ax.set_title('Sample Loadings by Component and Species')\n    \n    # Legend\n    from matplotlib.patches import Patch\n    legend_elements = [Patch(facecolor=species_colors[sp], label=sp) \n                      for sp in ['apul', 'peve', 'ptua']]\n    ax.legend(handles=legend_elements)\n    plt.tight_layout()\n    plt.savefig(os.path.join(figs_dir, 'sample_loadings.png'), dpi=200)\n    plt.close()\n\n\ndef main() -> None:\n    parser = argparse.ArgumentParser(\n        description='Build tensor (genes × timepoints × samples) and run Barnacle SparseCP')\n    parser.add_argument('--input-file', required=True, \n                       help='Path to merged vst_counts_matrix.csv file')\n    parser.add_argument('--output-dir', required=True, \n                       help='Output directory for results')\n    parser.add_argument('--rank', type=int, default=5)\n    parser.add_argument('--lambda-gene', type=float, default=0.1)\n    parser.add_argument('--lambda-time', type=float, default=0.05)\n    parser.add_argument('--lambda-sample', type=float, default=0.1)\n    parser.add_argument('--max-iter', type=int, default=1000)\n    parser.add_argument('--tol', type=float, default=1e-5)\n    parser.add_argument('--seed', type=int, default=42)\n    args = parser.parse_args()\n\n    if not os.path.exists(args.input_file):\n        raise FileNotFoundError(f\"Input file not found: {args.input_file}\")\n\n    df = read_normalized_csv(args.input_file)\n    tensor, sample_labels, sample_metadata, genes = build_tensor_by_sample(\n        df, expected_timepoints=[1, 2, 3, 4])\n\n    print(f\"\\nTensor shape: {tensor.shape}\")\n    print(f\"  Genes: {tensor.shape[0]}\")\n    print(f\"  Timepoints: {tensor.shape[1]}\")\n    print(f\"  Samples: {tensor.shape[2]}\")\n\n    model, decomposition = run_sparse_cp(\n        tensor=tensor,\n        rank=args.rank,\n        lambda_gene=args.lambda_gene,\n        lambda_time=args.lambda_time,\n        lambda_sample=args.lambda_sample,\n        max_iter=args.max_iter,\n        tol=args.tol,\n        seed=args.seed,\n    )\n\n    save_outputs(args.output_dir, tensor, sample_labels, sample_metadata, \n                genes, model, decomposition)\n\n\nif __name__ == '__main__':\n    main()\n```    \n\n\n### Output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(pheatmap)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.1.0\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngene_csv <-read.csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/50-tensor-alternative/barnacle_factors/gene_factors.csv\",\n               check.names = FALSE)\n\n# Replace column names\ncolnames(gene_csv) <- c(\"OG_ID\", paste0(\"Component_\", 1:(ncol(gene_csv)-1)))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime_csv <-read.csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/50-tensor-alternative/barnacle_factors/time_factors.csv\",\n               check.names = FALSE)\n\n# Replace column names\ncolnames(time_csv) <- c(\"Time_ID\", paste0(\"Component_\", 1:(ncol(time_csv)-1)))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Path to your CSV file\nsample_csv <- read.csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/50-tensor-alternative/barnacle_factors/sample_factors.csv\",\n               check.names = FALSE)\n\n# Replace column names\ncolnames(sample_csv) <- c(\"Sample\", paste0(\"Component_\", 1:(ncol(sample_csv)-1)))\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required libraries\nlibrary(readr)\nlibrary(pheatmap)\n\n\n\n# Make the first column row names\ndf_mat <- sample_csv |> \n  column_to_rownames(var = colnames(sample_csv)[1]) |> \n  as.matrix()\n\n# Optional: scale rows or columns for better contrast\ndf_scaled <- scale(df_mat)\n\n# Plot heatmap\npheatmap(df_scaled,\n         color = colorRampPalette(c(\"navy\",\"white\",\"firebrick3\"))(100),\n         clustering_method = \"ward.D2\",\n         show_rownames = TRUE,\n         show_colnames = TRUE,\n         main = \"Heatmap of Samples vs Features\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# Pivot to long format for plotting\ndf_long <- time_csv %>%\n  pivot_longer(\n    cols = starts_with(\"Component_\"),\n    names_to = \"Component\",\n    values_to = \"Value\"\n  )\n\n# Line plot\nggplot(df_long, aes(x = Time_ID, y = Value, group = Component, color = Component)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  ) +\n  labs(\n    title = \"Time Factor Loadings Across Components\",\n    x = \"Time Point\",\n    y = \"Loading Value\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n\n\n# Compute variance of each component across timepoints\nvar_components <- time_csv %>%\n  pivot_longer(cols = starts_with(\"Component_\"),\n               names_to = \"Component\",\n               values_to = \"Value\") %>%\n  group_by(Component) %>%\n  summarise(Variance = var(Value, na.rm = TRUE)) %>%\n  arrange(desc(Variance))\n\n# Select top 10 most variable components\ntop10_components <- var_components %>% slice_max(Variance, n = 10) %>% pull(Component)\n\n# Prepare data for plotting\ntime_csv_long <- time_csv %>%\n  pivot_longer(cols = starts_with(\"Component_\"),\n               names_to = \"Component\",\n               values_to = \"Value\") %>%\n  filter(Component %in% top10_components)\n\n# Line plot\nggplot(time_csv_long, aes(x = Time_ID, y = Value, group = Component, color = Component)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 2) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(\n    title = \"Top 10 Most Variable Components Across Timepoints\",\n    x = \"Time Point\",\n    y = \"Component Value\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n\n# ---- USER INPUT ----\n# Pick the component you want to plot (e.g., \"Component_5\")\nselected_component <- \"Component_5\"\n# ---------------------\n\n\n\n# Convert to long format\ndf_long <- time_csv %>%\n  pivot_longer(\n    cols = starts_with(\"Component_\"),\n    names_to = \"Component\",\n    values_to = \"Value\"\n  )\n\n# Check that the chosen component exists\nif (!(selected_component %in% unique(df_long$Component))) {\n  stop(paste(\"Component\", selected_component, \"not found in data!\"))\n}\n\n# Filter for the selected component\ndf_sel <- df_long %>% filter(Component == selected_component)\n\n# Plot single component across timepoints\nggplot(df_sel, aes(x = Time_ID, y = Value, group = 1)) +\n  geom_line(linewidth = 1.2, color = \"steelblue\") +\n  geom_point(size = 3, color = \"firebrick\") +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(\n    title = paste0(selected_component, \" Across Timepoints\"),\n    x = \"Time Point\",\n    y = \"Loading Value\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(pheatmap)\n\n\n\n# Convert to matrix (remove OG_ID column)\nmat <- gene_csv %>%\n  column_to_rownames(var = \"OG_ID\") %>%\n  as.matrix()\n\n\n# Optional: scale rows (genes) so colors represent relative loadings per gene\npheatmap(\n  mat,\n  scale = \"row\",\n  color = colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))(100),\n  clustering_method = \"ward.D2\",\n  show_rownames = FALSE,\n  main = \"Gene Factor Loadings (All Components)\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(pheatmap)\n\n\n# Convert to numeric matrix\nmat <- gene_csv %>%\n  column_to_rownames(var = \"OG_ID\") %>%\n  as.matrix()\n\n# Heatmap of actual (unscaled) values\npheatmap(\n  mat,\n  scale = \"none\",  # do not scale\n  color = colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))(200),\n  clustering_method = \"ward.D2\",\n  show_rownames = FALSE,\n  main = \"Gene Factor Loadings (Actual Values)\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n# More lamda testing\n\n\n``` bash\nLAMBDAS_GENE=\"0.00 0.1 0.2 0.4 0.8 1.0 10 40 100 1000\"\nLAMBDA_SAMPLE=0.1\nLAMBDA_TIME=0.05\nRANK=35\n\nmkdir -p ../output/40-rank35-optimization\n\nOUTDIR_BASE=../output/40-rank35-optimization\n\nfor LG in $LAMBDAS_GENE; do\n  OUTDIR=${OUTDIR_BASE}/lambda_gene_${LG}\n  mkdir -p \"$OUTDIR\"\n\n  uv run python ../scripts/14.1-barnacle/build_tensor_and_run.py \\\n    --input-file ../output/14-pca-orthologs/vst_counts_matrix.csv \\\n    --output-dir \"$OUTDIR\" \\\n    --rank $RANK \\\n    --lambda-gene $LG \\\n    --lambda-sample $LAMBDA_SAMPLE \\\n    --lambda-time $LAMBDA_TIME \\\n    --max-iter 1000 \\\n    --tol 1e-5 \\\n    --seed 92\ndone\n\n\n```\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_0.00/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_0.1/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_0.2/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_0.4/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_0.8/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_1.0/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_10/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_40/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_100/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  # Load data\n  gene_factors <- read_csv(\"https://gannet.fish.washington.edu/v1_web/owlshell/bu-github/timeseries_molecular/M-multi-species/output/40-rank35-optimization/lambda_gene_1000/barnacle_factors/gene_factors.csv\")\n\n\n#edit so columns names are shifted 1 to the left\n  colnames(gene_factors) <- c(\"gene\", paste0(\"comp\", 1:(ncol(gene_factors)-1)))\n\n#code to create histogram of gene_factors:\n  \n  library(ggplot2)\n  library(tidyr)\n  \n  # Reshape data to long format \n  gene_factors_long <- gene_factors %>%\n    pivot_longer(cols = -1, names_to = \"component\", values_to = \"loading\")\n  \n  # Plot histogram\n  ggplot(gene_factors_long, aes(x = loading)) +\n    geom_histogram(bins = 50, fill = \"blue\", alpha = 0.7) +\n    facet_wrap(~ component, scales = \"free\") +\n    theme_minimal() +\n    labs(title = \"Distribution of Gene Loadings for Rank 35 Components\",\n         x = \"Gene Loading\",\n         y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}